{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "opened-florist",
   "metadata": {},
   "source": [
    "# Pegasos Quantum Support Vector Classifier\n",
    "\n",
    "There's another SVM based algorithm that benefits from the quantum kernel method. Here, we introduce an implementation of a another classification algorithm, which is an alternative version to the `QSVC` available in Qiskit Machine Learning and shown in the [\"Quantum Kernel Machine Learning\"](./03_quantum_kernel.ipynb) tutorial. This classification algorithm implements the Pegasos algorithm from the paper \"Pegasos: Primal Estimated sub-GrAdient SOlver for SVM\" by Shalev-Shwartz et al., see: https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf.\n",
    "\n",
    "This algorithm is an alternative to the dual optimization from the `scikit-learn` package, benefits from the kernel trick, and yields a training complexity that is independent of the size of the training set. Thus, the `PegasosQSVC` is expected to train faster than QSVC for sufficiently large training sets.\n",
    "\n",
    "The algorithm can be used as direct replacement of `QSVC` with some hyper-parameterization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-painting",
   "metadata": {},
   "source": [
    "Let's generate some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressed-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (0.16.0)\n",
      "Requirement already satisfied: numpy<3,>=1.17 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (1.15.3)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (1.13.3)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (0.3.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (2.9.0.post0)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (4.12.2)\n",
      "Requirement already satisfied: symengine<0.14,>=0.11 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from qiskit) (0.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
      "Requirement already satisfied: pbr>=2.0.0 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from stevedore>=3.0.0->qiskit) (6.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lhlee\\anaconda3\\lib\\site-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
      "(20, 2) (20,)\n"
     ]
    }
   ],
   "source": [
    "# complete the code\n",
    "!pip install qiskit\n",
    "import sklearn \n",
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=20, n_features=2, centers = 2, random_state=3, shuffle = True )\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-yugoslavia",
   "metadata": {},
   "source": [
    "We pre-process the data to ensure compatibility with the rotation encoding and split it into the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adolescent-composer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.80519067  0.86322756]\n",
      " [ 1.99832549  3.06188882]\n",
      " [ 2.50210641  4.39967272]\n",
      " [-4.98567132 -2.20253107]\n",
      " [-4.53817598 -1.52658893]]\n",
      "[[0.         1.19272972]\n",
      " [2.95107648 2.04811626]\n",
      " [3.14159265 2.56857948]\n",
      " [0.30991982 0.        ]\n",
      " [0.47915032 0.26297448]]\n"
     ]
    }
   ],
   "source": [
    "# complete the code\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(X[:5])\n",
    "X = MinMaxScaler(feature_range = (0,np.pi)).fit_transform(X)\n",
    "print(X[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a13ede37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-poverty",
   "metadata": {},
   "source": [
    "We have two features in the dataset, so we set a number of qubits to the number of features in the dataset.\n",
    "\n",
    "Then we set $\\tau$ to the number of steps performed during the training procedure. Please note that, there is no early stopping criterion in the algorithm. The algorithm iterates over all $\\tau$ steps.\n",
    "\n",
    "And the last one is the hyperparameter $C$. This is a positive regularization parameter. The strength of the regularization is inversely proportional to $C$. Smaller $C$ induce smaller weights which generally helps preventing overfitting. However, due to the nature of this algorithm, some of the computation steps become trivial for larger $C$. Thus, larger $C$ improve the performance of the algorithm drastically. If the data is linearly separable in feature space, $C$ should be chosen to be large. If the separation is not perfect, $C$ should be chosen smaller to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dying-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits is equal to the number of features\n",
    "\n",
    "# number of steps performed during the training procedure\n",
    "\n",
    "# regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-wilderness",
   "metadata": {},
   "source": [
    "The algorithm will run using:\n",
    "\n",
    "- The default fidelity instantiated in `FidelityQuantumKernel`\n",
    "- A quantum kernel created from `ZFeatureMap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automated-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-stationery",
   "metadata": {},
   "source": [
    "The implementation `PegasosQSVC` is compatible with the `scikit-learn` interfaces and has a pretty standard way of training a model. In the constructor we pass parameters of the algorithm, in this case there are a regularization hyper-parameter $C$ and a number of steps.\n",
    "\n",
    "Then we pass training features and labels to the `fit` method, which trains a models and returns a fitted classifier.\n",
    "\n",
    "Afterwards, we score our model using test features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "representative-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c46d8508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit_machine_learning.algorithms.classifiers.pegasos_qsvc.PegasosQSVC at 0x173189e80>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5dec3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ffb854dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-empire",
   "metadata": {},
   "source": [
    "For visualization purposes we create a mesh grid of a predefined step that spans our minimum and maximum values we applied in MinMaxScaler. We also add some margin to the grid for better representation of the training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "judicial-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-constitution",
   "metadata": {},
   "source": [
    "We convert the grid to the shape compatible with the model, the shape should be `(n_samples, n_features)`.\n",
    "Then for each grid point we predict a label. In our case predicted labels will be used for coloring the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "competitive-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fa364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "former-constraint",
   "metadata": {},
   "source": [
    "Finally, we plot our grid according to the labels/colors we obtained from the model. We also plot training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monetary-knife",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meshgrid_colors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m meshgrid_colors \u001b[38;5;241m=\u001b[39m meshgrid_colors\u001b[38;5;241m.\u001b[39mreshape(grid_x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mpcolormesh(grid_x, grid_y, meshgrid_colors, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRdBu\u001b[39m\u001b[38;5;124m\"\u001b[39m, shading\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[0;32m      8\u001b[0m     x_train[:, \u001b[38;5;241m0\u001b[39m][y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m     x_train[:, \u001b[38;5;241m1\u001b[39m][y_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA train\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meshgrid_colors' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "meshgrid_colors = meshgrid_colors.reshape(grid_x.shape)\n",
    "plt.pcolormesh(grid_x, grid_y, meshgrid_colors, cmap=\"RdBu\", shading=\"auto\")\n",
    "\n",
    "plt.scatter(\n",
    "    x_train[:, 0][y_train == 0],\n",
    "    x_train[:, 1][y_train == 0],\n",
    "    marker=\"s\",\n",
    "    facecolors=\"w\",\n",
    "    edgecolors=\"r\",\n",
    "    label=\"A train\",\n",
    ")\n",
    "plt.scatter(\n",
    "    x_train[:, 0][y_train == 1],\n",
    "    x_train[:, 1][y_train == 1],\n",
    "    marker=\"o\",\n",
    "    facecolors=\"w\",\n",
    "    edgecolors=\"b\",\n",
    "    label=\"B train\",\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    x_test[:, 0][y_test == 0],\n",
    "    x_test[:, 1][y_test == 0],\n",
    "    marker=\"s\",\n",
    "    facecolors=\"r\",\n",
    "    edgecolors=\"r\",\n",
    "    label=\"A test\",\n",
    ")\n",
    "plt.scatter(\n",
    "    x_test[:, 0][y_test == 1],\n",
    "    x_test[:, 1][y_test == 1],\n",
    "    marker=\"o\",\n",
    "    facecolors=\"b\",\n",
    "    edgecolors=\"b\",\n",
    "    label=\"B test\",\n",
    ")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0.0)\n",
    "plt.title(\"Pegasos Classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "45066e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token + backend\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Sampler\n",
    "token = \"79232e64fa632d6dc52dbcba74585a33ec8593fe06d654771e8e3805d1cfb4f029a8d2b4dc022194164e29c2c16746342a7abc849cac0e6d9b2a726ab4785731\"\n",
    "service = QiskitRuntimeService(channel = \"ibm_quantum\", token = token)\n",
    "backend = service.backend('ibm_brisbane')\n",
    "sampler = Sampler(backend)\n",
    "X = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "47f150c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6000\n",
      "Test accuracy: 0.4000\n",
      "bckend = ibm_brisbane srart = 2025-04-29T01:02:17.862Z end = 2025-04-29T01:02:19.382Z elapsed_time = 0:00:01.520000 usage_seconds = 0         estimated_running_time_seconds = None\n"
     ]
    }
   ],
   "source": [
    "from qiskit import transpile, QuantumCircuit\n",
    "# Pegasos to a quantum backend\n",
    "# Feature map and quantum kernel\n",
    "feature_map = ZZFeatureMap(feature_dimension=X.shape[1], reps=2, entanglement=\"linear\")\n",
    "quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "feature_map_compiled = transpile(feature_map, backend=backend)\n",
    "\n",
    "# Create a quantum circuit for the kernel\n",
    "num_qubits = 127  # Adjust based on the backend capabilities\n",
    "quantum_kernel_circuit = QuantumCircuit(num_qubits)\n",
    "quantum_kernel_circuit.append(feature_map_compiled, range(num_qubits))\n",
    "# Use QuantumCircuit for FidelityQuantumKernel\n",
    "fidelity_quantum_kernel = FidelityQuantumKernel()\n",
    "fidelity_quantum_kernel._quantum_circuit = quantum_kernel_circuit\n",
    "# Pegasos QSVC model\n",
    "num_steps = 100  # You can tune this\n",
    "C = 1.0\n",
    "model = PegasosQSVC(quantum_kernel=fidelity_quantum_kernel, C=C, num_steps=num_steps)\n",
    "\n",
    "# Fit and evaluate\n",
    "model.fit(x_train, y_train)\n",
    "train_score = model.score(x_train, y_train)\n",
    "test_score = model.score(x_test, y_test)\n",
    "\n",
    "print(f\"Train accuracy: {train_score:.4f}\")\n",
    "print(f\"Test accuracy: {test_score:.4f}\")\n",
    "backend_info()\n",
    "#model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "13d7ac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datetime in /opt/miniconda3/lib/python3.12/site-packages (5.5)\n",
      "Requirement already satisfied: zope.interface in /opt/miniconda3/lib/python3.12/site-packages (from datetime) (7.2)\n",
      "Requirement already satisfied: pytz in /opt/miniconda3/lib/python3.12/site-packages (from datetime) (2025.1)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from zope.interface->datetime) (69.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49884b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrimitiveResult([SamplerPubResult(data=DataBin(c=BitArray(<shape=(), num_shots=4096, num_bits=5>)), metadata={'circuit_metadata': {}})], metadata={'execution': {'execution_spans': ExecutionSpans([SliceSpan(<start='2025-01-23 14:45:10', stop='2025-01-23 14:45:29', size=4096>)])}, 'version': 2})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List recent jobs submitted by the runtime service\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "service = QiskitRuntimeService(channel = \"ibm_quantum\", token = token)  # Ensure youâ€™ve authenticated\n",
    "jobs = service.jobs(limit=5, backend_name=\"ibm_brisbane\")  # You can also filter by job status\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "13332675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ad82d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# transfer function to top and call the function to the QSVC\n",
    "# chalenge: create quantum cluster with quantum backend (notebook 6.3)\n",
    "def difference(ended, created):# '2025-04-29T01:02:19.382Z' - '2025-04-29T01:02:17.862Z'\n",
    "    date_end = datetime.strptime(ended, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    date_created = datetime.strptime(created, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    time = date_end -date_created\n",
    "\n",
    "    return time\n",
    "def backend_info():\n",
    "    token = \"79232e64fa632d6dc52dbcba74585a33ec8593fe06d654771e8e3805d1cfb4f029a8d2b4dc022194164e29c2c16746342a7abc849cac0e6d9b2a726ab4785731\"\n",
    "    response = requests.request(\n",
    "        \"GET\",\n",
    "        \"https://api.quantum-computing.ibm.com/runtime/workloads/me\",\n",
    "        headers={\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer \" + token\n",
    "        },\n",
    "    )\n",
    "    #print(response.json())\n",
    "    json_res = response.json()\n",
    "    json_res['workloads'][0]\n",
    "    backend = json_res['workloads'][0][\"backend\"]\n",
    "    created = json_res['workloads'][0][\"created\"]\n",
    "    ended = json_res['workloads'][0][\"ended\"]\n",
    "    elapsed_time = difference(ended, created) #json_res['workloads'][0][\"usage_time\"]\n",
    "    usage_seconds = json_res['workloads'][0][\"usage_seconds\"]\n",
    "    estimated_running_time_seconds = json_res['workloads'][0][\"estimated_running_time_seconds\"]\n",
    "    print(f'bckend = {backend} srart = {created} end = {ended} elapsed_time = {elapsed_time} usage_seconds = {usage_seconds} \\\n",
    "        estimated_running_time_seconds = {estimated_running_time_seconds}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3f996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddc86e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fidelity_quantum_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqiskit_machine_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FidelityQuantumKernel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# QSVC\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize QSVC\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m qsvc \u001b[38;5;241m=\u001b[39m QSVC(quantum_kernel\u001b[38;5;241m=\u001b[39mfidelity_quantum_kernel)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train QSVC\u001b[39;00m\n\u001b[0;32m      9\u001b[0m qsvc\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fidelity_quantum_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.algorithms.classifiers import QSVC\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# QSVC\n",
    "# Initialize QSVC\n",
    "qsvc = QSVC(quantum_kernel=fidelity_quantum_kernel)\n",
    "\n",
    "# Train QSVC\n",
    "qsvc.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate QSVC\n",
    "score = qsvc.score(x_train, y_train)\n",
    "print(f\"Quantum Kernel QSVC Train Accuracy: {score:.4f}\")\n",
    "score = qsvc.score(x_test, y_test)\n",
    "print(f\"Quantum Kernel QSVC Test Accuracy: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224ddfe",
   "metadata": {},
   "source": [
    "- With the current QML methosd how can we aprimorate the performance, get less runtime. (speed up)\n",
    "\n",
    "- Is it worth the process to transform classical data in quantum data?\n",
    "\n",
    "- Once the data is transformed, the Qmodel is optimal then the traditional Qmodel?\n",
    "\n",
    "- The quantum computer suffer from error. So we can investigate quantum error correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49200aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1c86520",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
